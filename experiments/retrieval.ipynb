{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 ____       __       _                 __   ______            _ __      __     __\n",
    "                / __ \\___  / /______(_)__ _   ______ _/ /  / ____/___  ____  (_) /___  / /_   / /\n",
    "               / /_/ / _ \\/ __/ ___/ / _ \\ | / / __ `/ /  / /   / __ \\/ __ \\/ / / __ \\/ __/  / / \n",
    "              / _, _/  __/ /_/ /  / /  __/ |/ / /_/ / /  / /___/ /_/ / /_/ / / / /_/ / /_   /_/  \n",
    "             /_/ |_|\\___/\\__/_/  /_/\\___/|___/\\__,_/_/   \\____/\\____/ .___/_/_/\\____/\\__/  (_)   \n",
    "                                                                   /_/                           \n",
    "                                       (learning every nanosecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting code\n",
    "The goal of this algorithm is to retrieve a relevant code snippet given an English description and a series of already defined code/description pairs.\n",
    "![ret](../images/retrievalHighLevel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import pyndri\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import re, string, timeit\n",
    "from colored import fg, bg, attr\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tensor2tensor.utils import bleu_hook\n",
    "from multiprocessing import Process, Manager\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indri \n",
    "Indri is the retrieval engine that I am currently using since it has a nice interface with python and has some of the algorithms I need.\n",
    "\n",
    "Indri takes files in an XML format. Sentence pairs are usually stored line by line in a file. So we will need to convert from single line to formatted XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets \n",
    "We will currently make a full explanation for only one dataset: Django. This is because it is relatively small (18k sentences) and clean. Further descriptions and analysis are found in other notebooks in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(fp, src_ext=\".src\", tgt_ext=\".tgt\", lines=[3,21,80,99]):\n",
    "    linecache.clearcache()\n",
    "    for l in lines:\n",
    "        print(\"LINE: {} \\nSOURCE:    {} \\nTARGET:     {}\\n\".format(l, \n",
    "                                                                   linecache.getline(fp+src_ext, l), \n",
    "                                                                   linecache.getline(fp+tgt_ext, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE: 13 \n",
      "SOURCE:      define the function get_cache with backend and dictionary pair of elements kwargs as arguments.\n",
      " \n",
      "TARGET:         def get_cache ( backend , ** kwargs ) :\n",
      "\n",
      "\n",
      "LINE: 14 \n",
      "SOURCE:      call the function warnings.warn with string \"'get_cache' is deprecated in favor of 'caches'.\", RemovedInDjango19Warning,\n",
      " \n",
      "TARGET:      warnings . warn ( \"'get_cache' is deprecated in favor of 'caches'.\" ,  RemovedInDjango19Warning , stacklevel = 2 )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "django_fp = \"../datasets/django/all\"\n",
    "show_sample(django_fp, src_ext=\".desc\", tgt_ext=\".code\", lines=[13,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  from threading import local into default name space.\r\n",
      "  import module warnings.\r\n",
      "  from django.conf import settings into default name space.\r\n",
      "  from django.core import signals into default name space.\r\n",
      "  from django.core.cache.backends.base import InvalidCacheBackendError, CacheKeyWarning and BaseCache into default name space.\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../datasets/django/all.desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " from threading import local\r\n",
      " import warnings\r\n",
      "  from django . conf import settings\r\n",
      " from django . core import signals\r\n",
      " from django . core . cache . backends . base import (  InvalidCacheBackendError , CacheKeyWarning , BaseCache )\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../datasets/django/all.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  temp  already exists\n"
     ]
    }
   ],
   "source": [
    "dirName = \"temp\"\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and train / test split\n",
    "Copy the full dataset to the temp folder. We then split the data into a training and testing set at around 90% / 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9 # this means 90% of the data will be used for training, thus 10% for testing\n",
    "num_samples = sum(1 for line in open(django_fp + \".desc\"))\n",
    "train_cutoff = int(num_samples * train_ratio)\n",
    "\n",
    "lines = np.arange(num_samples)\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "train_lines = lines[:train_cutoff]\n",
    "test_lines = lines[train_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "train_fp = \"temp/retrieval_train\"\n",
    "test_fp = \"temp/retrieval_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train split for .desc and .code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_fp + \".desc\", \"w\") as out:\n",
    "    for l in train_lines:\n",
    "        src = linecache.getline(django_fp + \".desc\", l)\n",
    "        out.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_fp + \".code\", \"w\") as out:\n",
    "    for l in train_lines:\n",
    "        src = linecache.getline(django_fp + \".code\", l)\n",
    "        out.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test split for .desc and .code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_fp + \".desc\", \"w\") as out:\n",
    "    for l in test_lines:\n",
    "        src = linecache.getline(django_fp + \".desc\", l)\n",
    "        out.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_fp + \".code\", \"w\") as out:\n",
    "    for l in test_lines:\n",
    "        src = linecache.getline(django_fp + \".code\", l)\n",
    "        out.write(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TrecText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_fp + \".desc\", \"r\") as f, open(\"temp/train_desc.trectext\", \"w\") as out:\n",
    "    count = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        \n",
    "        if not line :\n",
    "            break\n",
    "            \n",
    "        out.write(\"<DOC>\\n  <DOCNO>{}</DOCNO>\\n  <TEXT>\\n{}  </TEXT>\\n</DOC>\\n\".format(count, line))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index with indri\n",
    "To create an index we need to supply Indri with a parameter file specifying how to handle each document. Indri will then generate an index folder with is fast to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/IndriBuildIndex.conf\", \"w\") as out:\n",
    "    conf = \"\"\"\n",
    "<parameters>\n",
    "<index>temp/django_index/</index>\n",
    "<memory>1024M</memory>\n",
    "<storeDocs>true</storeDocs>\n",
    "<corpus><path>temp/train_desc.trectext</path><class>trectext</class></corpus>\n",
    "<stemmer><name>krovetz</name></stemmer>\n",
    "</parameters>\"\"\"\n",
    "    \n",
    "    out.write(conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kstem_add_table_entry: Duplicate word emeritus will be ignored.\n",
      "kstem_add_table_entry: Duplicate word emeritus will be ignored.\n",
      "0:00: Opened repository temp/django_index/\n",
      "0:00: Opened temp/train_desc.trectext\n",
      "0:00: Documents parsed: 16923 Documents indexed: 0\n",
      "0:00: Closed temp/train_desc.trectext\n",
      "0:00: Closing index\n",
      "0:00: Finished\n"
     ]
    }
   ],
   "source": [
    "!IndriBuildIndex temp/IndriBuildIndex.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pyndri.Index(\"temp/django_index/\")\n",
    "env = pyndri.TFIDFQueryEnvironment(index, k1=1.2, b=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = env.query('error handler', results_requested=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE: 1718 \n",
      "SOURCE:      define the method resolve_error_handler with arguments self and view_type.\n",
      " \n",
      "TARGET:        def resolve_error_handler ( self , view_type ) :\n",
      "\n",
      "\n",
      "LINE: 15350 \n",
      "SOURCE:      for every handler in handlers,\n",
      " \n",
      "TARGET:                               for handler in handlers :\n",
      "\n",
      "\n",
      "LINE: 10247 \n",
      "SOURCE:      for every handler in handlers,\n",
      " \n",
      "TARGET:          for handler in handlers :\n",
      "\n",
      "\n",
      "LINE: 6919 \n",
      "SOURCE:      substitute self._upload_handlers for handlers.\n",
      " \n",
      "TARGET:      handlers = self . _upload_handlers\n",
      "\n",
      "\n",
      "LINE: 2756 \n",
      "SOURCE:      substitute upload_handlers for self._upload_handlers.\n",
      " \n",
      "TARGET:       self . _upload_handlers = upload_handlers\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sample(train_fp, src_ext=\".desc\", tgt_ext=\".code\", lines=[doc[0] for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_code = [linecache.getline(django_fp + \".code\", doc[0]) for doc in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove punctuation from input query strings so that Indri accepts them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[^\\w\\s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE: 1 \n",
      "\u001b[38;5;24m\u001b[48;5;85mQUERY:\u001b[0m      raise a ValidationError exception with 2 arguments: return value of the function _ called with an argument string 'Enter a valid IPv6 address.', and code set to string 'invalid'.\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED DESCRIPTION:\u001b[0m      raise a ValidationError exception with 2 arguments: return value of the function _ called with an argument string 'Enter a valid IPv4 or IPv6 address.', and code set to string 'invalid'.\n",
      " \n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED CODE:\u001b[0m                   raise ValidationError ( _ ( 'Enter a valid IPv4 or IPv6 address.' ) , code = 'invalid' )\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;85mTRUTH:\u001b[0m              raise ValidationError ( _ ( 'Enter a valid IPv6 address.' ) , code = 'invalid' )\n",
      "\n",
      "\n",
      "LINE: 501 \n",
      "\u001b[38;5;24m\u001b[48;5;85mQUERY:\u001b[0m      convert max_entries into a string, substitute it for self._max_entries.\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED DESCRIPTION:\u001b[0m      convert self into a string and return it.\n",
      " \n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED CODE:\u001b[0m               return str ( self )\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;85mTRUTH:\u001b[0m                  self . _max_entries = int ( max_entries )\n",
      "\n",
      "\n",
      "LINE: 1001 \n",
      "\u001b[38;5;24m\u001b[48;5;85mQUERY:\u001b[0m      define the method add with 5 arguments, self class instance, key, value, timeout set to DEFAULT_TIMEOUT and version set to None.\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED DESCRIPTION:\u001b[0m      define the method add with 5 arguments, self class instance, key, value, timeout set to DEFAULT_TIMEOUT and version set to None.\n",
      " \n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED CODE:\u001b[0m        def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;85mTRUTH:\u001b[0m       def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :\n",
      "\n",
      "\n",
      "LINE: 1501 \n",
      "\u001b[38;5;24m\u001b[48;5;85mQUERY:\u001b[0m      raise an TemplateSyntaxError exception with an argument string \"'for' tag received an invalid argument: %s\",\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED DESCRIPTION:\u001b[0m      raise an TemplateSyntaxError exception with an argument \"'%s' received unexpected keyword argument '%s'\",\n",
      " \n",
      "\u001b[38;5;24m\u001b[48;5;153mPRED CODE:\u001b[0m                        raise TemplateSyntaxError (  \"'%s' received unexpected keyword argument '%s'\" %  ( name , param ) )\n",
      "\n",
      "\u001b[38;5;24m\u001b[48;5;85mTRUTH:\u001b[0m                  raise TemplateSyntaxError ( \"'for' tag received an invalid argument:\"  \" %s\" % token . contents )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linecache.clearcache()\n",
    "with open(test_fp + \".desc\", \"r\") as f, open(\"temp/retrieval_predictions\" + \".code\", \"w\") as out:\n",
    "    lines = f.readlines()\n",
    "    l = 1\n",
    "    for line in lines:\n",
    "        result = env.query(pattern.sub(\" \", line), results_requested=1)\n",
    "        if result != ():\n",
    "            out.write(linecache.getline(train_fp + \".code\",result[0][0]))\n",
    "        else:\n",
    "            out.write(\"\\n\")\n",
    "            print(\"LINE: {} \\n{}{}QUERY:{}    {}\\nSANITIZED QUERY      {}\\n{}{}PRED DESCRIPTION{}:   ######### NO PREDICTION ##########\\n\".format(\n",
    "                l, \n",
    "                fg(24), \n",
    "                bg(85),\n",
    "                attr(0),\n",
    "                line,\n",
    "                fg(24), \n",
    "                bg(217),\n",
    "                attr(0),\n",
    "                line.translate(str.maketrans('', '', string.punctuation))))\n",
    "        if l % 500 == 1:\n",
    "            print(\"LINE: {} \\n{}{}QUERY:{}    {}\\n{}{}PRED DESCRIPTION:{}    {} \\n{}{}PRED CODE:{}     {}\\n{}{}TRUTH:{}    {}\\n\".format(\n",
    "                l, \n",
    "                fg(24), \n",
    "                bg(85),\n",
    "                attr(0),\n",
    "                line, \n",
    "                fg(24), \n",
    "                bg(153),\n",
    "                attr(0),\n",
    "                linecache.getline(train_fp + \".desc\", result[0][0]), \n",
    "                fg(24), \n",
    "                bg(153),\n",
    "                attr(0),\n",
    "                linecache.getline(train_fp + \".code\", result[0][0]),\n",
    "                fg(24), \n",
    "                bg(85),\n",
    "                attr(0),\n",
    "                linecache.getline(test_fp + \".code\", l)))\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating BLEU Score\n",
    "We use a librarry from Google's tensor2tensor library. This way we ensure the methods are correct by being actively maintained. The method takes two files and compares them line by line.\n",
    "\n",
    "The only disadvantage is that it doesn't work with TF2.0 yet. Curently using TF1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 23:07:14.371142 140469340874496 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/tensor2tensor/utils/bleu_hook.py:205: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU_uncased =  37.13\n"
     ]
    }
   ],
   "source": [
    "bleu = 100 * bleu_hook.bleu_wrapper(\"temp/retrieval_test.code\", \"temp/retrieval_predictions.code\",\n",
    "                                          case_sensitive=False)\n",
    "print(\"BLEU_uncased = %6.2f\" % bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "In order to make fast optimisations we will use a multiprocessing library to fully utilise our hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_task = {\n",
    "        \"job_id\":0,\n",
    "        \"train_fp\":\"temp/retrieval_train\",\n",
    "        \"test_fp\":\"temp/retrieval_test\",\n",
    "        \"src_ext\":\".desc\",\n",
    "        \"tgt_ext\":\".code\",\n",
    "        \"hyps\":{\n",
    "            \"b\":0.75,\n",
    "            \"k1\":1.2\n",
    "        },\n",
    "        \"env\":pyndri.TFIDFQueryEnvironment(index, k1=1.2, b=0.75),\n",
    "        \"folds\":1,\n",
    "        \"fold\":1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_task_generator(task, k1s=[1.0, 1.5, 2.0], bs=[0.0,0.25,0.5,0.75,1.0]):\n",
    "    global uid\n",
    "    tasks = [] \n",
    "    for k1 in k1s:\n",
    "        for b in bs:\n",
    "            new_task = dict(task)\n",
    "            new_task[\"hyps\"] = {\"b\":b, \"k1\":k1}\n",
    "            new_task[\"env\"] = pyndri.TFIDFQueryEnvironment(index, k1=k1, b=b)\n",
    "            new_task[\"job_id\"] = uid\n",
    "            uid += 1\n",
    "            tasks.append(new_task)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks += TFIDF_task_generator(base_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'env': <pyndri.TFIDFQueryEnvironment at 0x7fc169bf0900>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.0, 'k1': 1.0},\n",
       "  'job_id': 0,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f168>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.25, 'k1': 1.0},\n",
       "  'job_id': 1,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f0d8>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.5, 'k1': 1.0},\n",
       "  'job_id': 2,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f1f8>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.75, 'k1': 1.0},\n",
       "  'job_id': 3,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f6c0>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 1.0, 'k1': 1.0},\n",
       "  'job_id': 4,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f5a0>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.0, 'k1': 1.5},\n",
       "  'job_id': 5,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f750>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.25, 'k1': 1.5},\n",
       "  'job_id': 6,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f708>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.5, 'k1': 1.5},\n",
       "  'job_id': 7,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f7e0>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.75, 'k1': 1.5},\n",
       "  'job_id': 8,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f828>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 1.0, 'k1': 1.5},\n",
       "  'job_id': 9,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f900>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.0, 'k1': 2.0},\n",
       "  'job_id': 10,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f870>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.25, 'k1': 2.0},\n",
       "  'job_id': 11,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f8b8>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.5, 'k1': 2.0},\n",
       "  'job_id': 12,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f990>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 0.75, 'k1': 2.0},\n",
       "  'job_id': 13,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'},\n",
       " {'env': <pyndri.TFIDFQueryEnvironment at 0x7fc142e1f9d8>,\n",
       "  'fold': 1,\n",
       "  'folds': 1,\n",
       "  'hyps': {'b': 1.0, 'k1': 2.0},\n",
       "  'job_id': 14,\n",
       "  'src_ext': '.desc',\n",
       "  'test_fp': 'temp/retrieval_test',\n",
       "  'tgt_ext': '.code',\n",
       "  'train_fp': 'temp/retrieval_train'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(task):\n",
    "    print(task[\"hyps\"], task[\"job_id\"])\n",
    "    linecache.clearcache()\n",
    "    env = task[\"env\"]\n",
    "    \n",
    "    out_file_name = \"temp/retrieval_predictions_fold:{}-{}_k1_{}_b_{}\".format(\n",
    "                                                                            task[\"fold\"],\n",
    "                                                                            task[\"folds\"],\n",
    "                                                                            task[\"hyps\"][\"k1\"],\n",
    "                                                                            task[\"hyps\"][\"b\"])\n",
    "    with open(task[\"test_fp\"] + \".desc\", \"r\") as f, open(out_file_name + \".code\", \"w\") as out:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            result = env.query(pattern.sub(\" \", line), results_requested=1)\n",
    "            if result != ():\n",
    "                out.write(linecache.getline(task[\"train_fp\"] + \".code\",result[0][0]))\n",
    "            else:\n",
    "                out.write(\"\\n\")\n",
    "                \n",
    "    bleu = 100 * bleu_hook.bleu_wrapper(task[\"test_fp\"] + \".code\", out_file_name + \".code\",\n",
    "                                          case_sensitive=False)\n",
    "                \n",
    "    task[\"BLEU\"] = bleu\n",
    "    measures.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k1': 1.0, 'b': 0.0} 0\n",
      "{'k1': 1.0, 'b': 0.5} 2\n",
      "{'k1': 1.0, 'b': 0.75} 3\n",
      "{'k1': 1.0, 'b': 0.25} 1\n",
      "{'k1': 1.0, 'b': 1.0} 4\n",
      "{'k1': 1.5, 'b': 0.0} 5\n",
      "{'k1': 1.5, 'b': 0.25} 6\n",
      "{'k1': 1.5, 'b': 0.75} 8\n",
      "{'k1': 1.5, 'b': 1.0} 9\n",
      "{'k1': 1.5, 'b': 0.5} 7\n",
      "{'k1': 2.0, 'b': 0.0} 10\n",
      "{'k1': 2.0, 'b': 0.25} 11\n",
      "{'k1': 2.0, 'b': 0.5} 12\n",
      "{'k1': 2.0, 'b': 0.75} 13\n",
      "{'k1': 2.0, 'b': 1.0} 14\n"
     ]
    }
   ],
   "source": [
    "with Manager() as manager:\n",
    "    measures = manager.list()\n",
    "    processes = []\n",
    "    for task in tasks:\n",
    "        p = Process(target=train_eval, args=(task,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        measures = list(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 7, 14, 3, 2, 4, 1, 13, 8, 10, 5, 6, 11, 12, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[\"job_id\"] for m in measures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'b': 1.0, 'k1': 1.5}, 32.57192671298981),\n",
       " ({'b': 0.5, 'k1': 1.5}, 33.298951387405396),\n",
       " ({'b': 1.0, 'k1': 2.0}, 30.727407336235046),\n",
       " ({'b': 0.75, 'k1': 1.0}, 37.75593340396881),\n",
       " ({'b': 0.5, 'k1': 1.0}, 33.298060297966),\n",
       " ({'b': 1.0, 'k1': 1.0}, 35.48528254032135),\n",
       " ({'b': 0.25, 'k1': 1.0}, 27.687522768974304),\n",
       " ({'b': 0.75, 'k1': 2.0}, 35.04375219345093),\n",
       " ({'b': 0.75, 'k1': 1.5}, 36.403024196624756),\n",
       " ({'b': 0.0, 'k1': 2.0}, 20.81363797187805),\n",
       " ({'b': 0.0, 'k1': 1.5}, 21.450144052505493),\n",
       " ({'b': 0.25, 'k1': 1.5}, 27.032572031021118),\n",
       " ({'b': 0.25, 'k1': 2.0}, 26.073500514030457),\n",
       " ({'b': 0.5, 'k1': 2.0}, 32.88987576961517),\n",
       " ({'b': 0.0, 'k1': 1.0}, 22.978107631206512)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m[\"hyps\"], m[\"BLEU\"]) for m in measures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
