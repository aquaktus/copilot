{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                 ____       __       _                 __   ______            _ __      __     __\n",
    "                / __ \\___  / /______(_)__ _   ______ _/ /  / ____/___  ____  (_) /___  / /_   / /\n",
    "               / /_/ / _ \\/ __/ ___/ / _ \\ | / / __ `/ /  / /   / __ \\/ __ \\/ / / __ \\/ __/  / / \n",
    "              / _, _/  __/ /_/ /  / /  __/ |/ / /_/ / /  / /___/ /_/ / /_/ / / / /_/ / /_   /_/  \n",
    "             /_/ |_|\\___/\\__/_/  /_/\\___/|___/\\__,_/_/   \\____/\\____/ .___/_/_/\\____/\\__/  (_)   \n",
    "                                                                   /_/                           \n",
    "                                       (learning every nanosecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting code\n",
    "The goal of this algorithm is to retrieve a relevant code snippet given an English description and a series of already defined code/description pairs.\n",
    "![ret](../images/retrievalHighLevel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import pyndri\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indri \n",
    "Indri is the retrieval engine that I am currently using since it has a nice interface with python and has some of the algorithms I need.\n",
    "\n",
    "Indri takes files in an XML format. Sentence pairs are usually stored line by line in a file. So we will need to convert from single line to formatted XML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets \n",
    "We will currently make a full explanation for only one dataset: Django. This is because it is relatively small (18k sentences) and clean. Further descriptions and analysis are found in other notebooks in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(fp, src_ext=\".src\", tgt_ext=\".tgt\", lines=[3,21,80,99]):\n",
    "    for l in lines:\n",
    "        print(\"LINE: {} \\nSOURCE:    {} \\nTARGET:     {}\\n\".format(l, \n",
    "                                                                   linecache.getline(fp+src_ext, l), \n",
    "                                                                   linecache.getline(fp+tgt_ext, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE: 13 \n",
      "SOURCE:      define the function get_cache with backend and dictionary pair of elements kwargs as arguments.\n",
      " \n",
      "TARGET:         def get_cache ( backend , ** kwargs ) :\n",
      "\n",
      "\n",
      "LINE: 14 \n",
      "SOURCE:      call the function warnings.warn with string \"'get_cache' is deprecated in favor of 'caches'.\", RemovedInDjango19Warning,\n",
      " \n",
      "TARGET:      warnings . warn ( \"'get_cache' is deprecated in favor of 'caches'.\" ,  RemovedInDjango19Warning , stacklevel = 2 )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "django_fp = \"../datasets/django/all\"\n",
    "show_sample(django_fp, src_ext=\".desc\", tgt_ext=\".code\", lines=[13,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  from threading import local into default name space.\r\n",
      "  import module warnings.\r\n",
      "  from django.conf import settings into default name space.\r\n",
      "  from django.core import signals into default name space.\r\n",
      "  from django.core.cache.backends.base import InvalidCacheBackendError, CacheKeyWarning and BaseCache into default name space.\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../datasets/django/all.desc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " from threading import local\r\n",
      " import warnings\r\n",
      "  from django . conf import settings\r\n",
      " from django . core import signals\r\n",
      " from django . core . cache . backends . base import (  InvalidCacheBackendError , CacheKeyWarning , BaseCache )\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 ../datasets/django/all.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  temp  Created \n"
     ]
    }
   ],
   "source": [
    "dirName = \"temp\"\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to TrecText format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(django_fp + \".desc\", \"r\") as f, open(\"temp/django_desc.trectext\", \"w\") as out:\n",
    "    count = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        \n",
    "        if not line :\n",
    "            break\n",
    "            \n",
    "        out.write(\"<DOC>\\n  <DOCNO>{}</DOCNO>\\n  <TEXT>\\n{}  </TEXT>\\n</DOC>\\n\".format(count, line))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the index with indri\n",
    "To create an index we need to supply Indri with a parameter file specifying how to handle each document. Indri will then generate an index folder with is fast to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/IndriBuildIndex.conf\", \"w\") as out:\n",
    "    conf = \"\"\"\n",
    "<parameters>\n",
    "<index>temp/django_index/</index>\n",
    "<memory>1024M</memory>\n",
    "<storeDocs>true</storeDocs>\n",
    "<corpus><path>temp/django_desc.trectext</path><class>trectext</class></corpus>\n",
    "<stemmer><name>krovetz</name></stemmer>\n",
    "</parameters>\"\"\"\n",
    "    \n",
    "    out.write(conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kstem_add_table_entry: Duplicate word emeritus will be ignored.\n",
      "0:00: Created repository temp/django_index/\n",
      "0:00: Opened temp/django_desc.trectext\n",
      "0:10: Documents parsed: 18805 Documents indexed: 18805\n",
      "0:10: Closed temp/django_desc.trectext\n",
      "0:10: Closing index\n",
      "0:11: Finished\n"
     ]
    }
   ],
   "source": [
    "!IndriBuildIndex temp/IndriBuildIndex.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pyndri.Index(\"temp/django_index/\")\n",
    "env = pyndri.TFIDFQueryEnvironment(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = env.query('for every handler in handlers', results_requested=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINE: 9733 \n",
      "SOURCE:      for every handler in handlers,\n",
      " \n",
      "TARGET:         for handler in handlers :\n",
      "\n",
      "\n",
      "LINE: 9698 \n",
      "SOURCE:      for every handler in handlers,\n",
      " \n",
      "TARGET:                               for handler in handlers :\n",
      "\n",
      "\n",
      "LINE: 9650 \n",
      "SOURCE:      for every handler in handlers,\n",
      " \n",
      "TARGET:          for handler in handlers :\n",
      "\n",
      "\n",
      "LINE: 9747 \n",
      "SOURCE:      for every handler in self._upload_handlers,\n",
      " \n",
      "TARGET:                  for handler in self . _upload_handlers :\n",
      "\n",
      "\n",
      "LINE: 10074 \n",
      "SOURCE:      for every handler in settings.FILE_UPLOAD_HANDLERS,\n",
      " \n",
      "TARGET:               self . _upload_handlers = [ uploadhandler . load_handler ( handler , self )  for handler in settings . FILE_UPLOAD_HANDLERS ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sample(django_fp, src_ext=\".desc\", tgt_ext=\".code\", lines=[doc[0] for doc in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_code = [linecache.getline(django_fp + \".code\", doc[0]) for doc in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
